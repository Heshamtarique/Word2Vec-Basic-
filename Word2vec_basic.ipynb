{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the relevant libraires.\n",
    "import pandas as pd\n",
    "import numpy as np      \n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We are going to do natural language processing of some text in hand, so we will use the library calleld Natural Language Tool Kit of python. \n",
    "### We will prefer dense representation of the feature in the form of vector rather than sparse representation(as we did in the last experiment by using bag of words model or TfIdf vectorization). Word2Vec is already present in gensim library which we will import here. \n",
    "### We have to some text preprocessing so we will import stopswords from nltk, and to deal with regular expressions we will use re."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets consider a recent article written by Mehdi Hasan in \"The Interept\"\n",
    "\n",
    "article = \"\"\"IF ANTI-SEMITISM is the world’s oldest hatred, perhaps Islamophobia is the world’s weirdest.\n",
    "         How else to explain the fact that a pandemic of global and historic proportions, \n",
    "         a novel coronavirus that is infecting people in almost every country and territory on Earth, \n",
    "         has been weaponized by the far right to attack … Islam and Muslims?\n",
    "         Take India, where the spread of the virus has been dubbed a “corona jihad” by supporters of the far-right BJP government; \n",
    "         they  claim the pandemic is a conspiracy by Muslims to infect and poison Hindus. \n",
    "         The government itself has blamed around a third of India’s confirmed Covid-19 cases on a gathering held in Delhi by a conservative Muslim missionary group called the Tablighi Jamaat; \n",
    "         one BJP minister called it a “Talibani crime.” As The Guardian reports, “Muslims have now seen their businesses across India boycotted, volunteers distributing rations called ‘coronavirus terrorists’, \n",
    "         and others accused of spitting in food and infecting water supplies with the virus. \n",
    "         Posters have appeared barring Muslims from entering certain neighbourhoods in states as far apart as Delhi, Karnataka, Telangana and Madhya Pradesh.” \n",
    "         There have even been reports of Indian Muslims being attacked, beaten, and lynched.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we need to process this data before feeding it to the algorithm. we will remove the letters other than a-z or A-Z by spaces. We will lower the sentance so that it may not be considered 2 different word while tokenizing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = re.sub(r'\\[[0-9]*\\]',' ',article)\n",
    "text = re.sub(r'\\s+',' ',text)\n",
    "text = text.lower()\n",
    "text = re.sub(r'\\d',' ',text)\n",
    "text = re.sub(r'\\s+',' ',text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "if anti-semitism is the world’s oldest hatred, perhaps islamophobia is the world’s weirdest. how else to explain the fact that a pandemic of global and historic proportions, a novel coronavirus that is infecting people in almost every country and territory on earth, has been weaponized by the far right to attack … islam and muslims? take india, where the spread of the virus has been dubbed a “corona jihad” by supporters of the far-right bjp government; they claim the pandemic is a conspiracy by muslims to infect and poison hindus. the government itself has blamed around a third of india’s confirmed covid- cases on a gathering held in delhi by a conservative muslim missionary group called the tablighi jamaat; one bjp minister called it a “talibani crime.” as the guardian reports, “muslims have now seen their businesses across india boycotted, volunteers distributing rations called ‘coronavirus terrorists’, and others accused of spitting in food and infecting water supplies with the virus. posters have appeared barring muslims from entering certain neighbourhoods in states as far apart as delhi, karnataka, telangana and madhya pradesh.” there have even been reports of indian muslims being attacked, beaten, and lynched.\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = nltk.sent_tokenize(text)\n",
    "sentences = [nltk.word_tokenize(sentence) for sentence in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['if', 'anti-semitism', 'is', 'the', 'world', '’', 's', 'oldest', 'hatred', ',', 'perhaps', 'islamophobia', 'is', 'the', 'world', '’', 's', 'weirdest', '.'], ['how', 'else', 'to', 'explain', 'the', 'fact', 'that', 'a', 'pandemic', 'of', 'global', 'and', 'historic', 'proportions', ',', 'a', 'novel', 'coronavirus', 'that', 'is', 'infecting', 'people', 'in', 'almost', 'every', 'country', 'and', 'territory', 'on', 'earth', ',', 'has', 'been', 'weaponized', 'by', 'the', 'far', 'right', 'to', 'attack', '…', 'islam', 'and', 'muslims', '?'], ['take', 'india', ',', 'where', 'the', 'spread', 'of', 'the', 'virus', 'has', 'been', 'dubbed', 'a', '“', 'corona', 'jihad', '”', 'by', 'supporters', 'of', 'the', 'far-right', 'bjp', 'government', ';', 'they', 'claim', 'the', 'pandemic', 'is', 'a', 'conspiracy', 'by', 'muslims', 'to', 'infect', 'and', 'poison', 'hindus', '.'], ['the', 'government', 'itself', 'has', 'blamed', 'around', 'a', 'third', 'of', 'india', '’', 's', 'confirmed', 'covid-', 'cases', 'on', 'a', 'gathering', 'held', 'in', 'delhi', 'by', 'a', 'conservative', 'muslim', 'missionary', 'group', 'called', 'the', 'tablighi', 'jamaat', ';', 'one', 'bjp', 'minister', 'called', 'it', 'a', '“', 'talibani', 'crime.', '”', 'as', 'the', 'guardian', 'reports', ',', '“', 'muslims', 'have', 'now', 'seen', 'their', 'businesses', 'across', 'india', 'boycotted', ',', 'volunteers', 'distributing', 'rations', 'called', '‘', 'coronavirus', 'terrorists', '’', ',', 'and', 'others', 'accused', 'of', 'spitting', 'in', 'food', 'and', 'infecting', 'water', 'supplies', 'with', 'the', 'virus', '.'], ['posters', 'have', 'appeared', 'barring', 'muslims', 'from', 'entering', 'certain', 'neighbourhoods', 'in', 'states', 'as', 'far', 'apart', 'as', 'delhi', ',', 'karnataka', ',', 'telangana', 'and', 'madhya', 'pradesh.', '”', 'there', 'have', 'even', 'been', 'reports', 'of', 'indian', 'muslims', 'being', 'attacked', ',', 'beaten', ',', 'and', 'lynched', '.']]\n"
     ]
    }
   ],
   "source": [
    "print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(sentences)):\n",
    "    sentences[i] = [word for word in sentences[i] if word not in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the word2vec model considering the minimum occurance of the word as 1- \n",
    "model = Word2Vec(sentences, min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = model.wv.vocab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-3.1264641e-03 -2.9059357e-03  1.0375759e-03 -3.0514156e-03\n",
      " -2.3237388e-03  6.3857087e-04  2.6456636e-04 -1.5250850e-03\n",
      "  3.3744215e-03 -4.4710031e-03 -3.1875023e-03 -4.5006420e-03\n",
      " -1.1213443e-03 -4.4077742e-03 -3.6930039e-03  3.7592514e-03\n",
      "  2.9179500e-03 -1.1625045e-03  6.7361572e-05  2.7181485e-03\n",
      " -4.0728776e-03 -2.7602369e-03  1.9003811e-03 -3.7428536e-03\n",
      "  8.0897444e-04 -2.4602506e-03  2.9210597e-03 -4.5005693e-03\n",
      "  2.6600168e-03  6.5347500e-04 -4.2198501e-03  1.8003857e-03\n",
      "  2.2401854e-03  1.2413579e-03  1.3415581e-03  3.0442514e-03\n",
      "  9.4173965e-04  7.7718223e-04 -3.3256772e-04 -1.0817115e-03\n",
      "  2.0343505e-03 -1.3499880e-03 -1.6717809e-03 -1.6276945e-03\n",
      "  3.1909265e-03  4.4709551e-03 -4.0994696e-03 -3.8776046e-03\n",
      " -3.4273393e-03 -4.3779886e-03 -3.0456026e-04 -1.2472275e-03\n",
      "  3.7628012e-03  2.4529642e-03 -2.9022710e-03  2.5340314e-03\n",
      " -8.4455899e-04 -4.9186759e-03 -9.3633018e-04  2.9548816e-03\n",
      " -1.9198323e-03  3.5030686e-03  1.3651797e-03 -3.5942460e-03\n",
      " -2.6136099e-03  2.8513728e-03  4.9007768e-03  4.1575781e-03\n",
      "  2.7933908e-03  3.1353761e-03 -4.7577838e-03 -1.2311366e-04\n",
      "  5.5748702e-04  1.1512579e-05  2.0092805e-03 -1.3350482e-03\n",
      "  4.8443461e-03  5.2673509e-04  3.0029465e-03 -4.3479685e-04\n",
      "  4.7156923e-03  2.0920297e-03 -2.4496710e-03 -2.4042763e-03\n",
      " -4.5383889e-03  4.9971580e-03  5.8526901e-04 -1.6937811e-03\n",
      "  6.1350351e-04  1.2621006e-03  7.4750109e-04 -1.6288478e-03\n",
      "  3.0047751e-03 -4.3742705e-04 -4.3757781e-03  2.6416066e-04\n",
      "  2.5003490e-03 -2.7159837e-03  4.9822256e-03 -3.9873458e-03]\n"
     ]
    }
   ],
   "source": [
    "# Finding Word Vectors\n",
    "vector = model.wv['muslims']\n",
    "print(vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here we can see that we can find the most relevant words to a word and this can give us a good idea of the corpus. This was quite intutive here as we had a very small corpus, this same concept can be applied to the large corpus and several information can be extracted out of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('islamophobia', 0.3313627541065216), ('minister', 0.29300034046173096), ('india', 0.18036605417728424), ('country', 0.16394412517547607), ('posters', 0.1507246345281601), ('gathering', 0.1422102004289627), ('guardian', 0.1420024037361145), ('poison', 0.12978433072566986), ('infecting', 0.12950587272644043), ('lynched', 0.11994846910238266)]\n"
     ]
    }
   ],
   "source": [
    "similar = model.wv.most_similar('muslims')\n",
    "print(similar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
